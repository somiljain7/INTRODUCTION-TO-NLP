# 1)sent_tokenize : tokenize a document into sentence
# 2)regexp_tokenize : tokenize a string or document based on a regular expression patter
# 3)tweet_tokenizer : special class just for tweet tokenization allowing you to separate hashtags, mentions and lots of exclamation points

# re.search() vs re.match()
  re.search more efficient in comparing letters
   as re.search searches letters in words whereas in math starting letters matters the most
